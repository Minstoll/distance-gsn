{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regular_biconnected_graph(d, n, max_tries=10):\n",
    "    \"\"\"\n",
    "    Generate a d-regular biconnected graph with n nodes.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_tries):\n",
    "        try:\n",
    "            G = nx.random_regular_graph(d, n)\n",
    "            if nx.is_biconnected(G):\n",
    "                return G\n",
    "        except nx.exception.NetworkXError:\n",
    "            continue\n",
    "    raise ValueError(f\"Failed to generate a {d}-regular biconnected graph with {n} nodes after {max_tries} tries.\")\n",
    "\n",
    "def find_disjoint_edge_pairs(G, num_pairs):\n",
    "    \"\"\"\n",
    "    Find 'num_pairs' disjoint edges in G.\n",
    "    Returns a list of tuples representing the edge pairs.\n",
    "    \"\"\"\n",
    "    edges = list(G.edges())\n",
    "    random.shuffle(edges)\n",
    "    selected_pairs = []\n",
    "    used_nodes = set()\n",
    "    for u, v in edges:\n",
    "        if u not in used_nodes and v not in used_nodes:\n",
    "            selected_pairs.append((u, v))\n",
    "            used_nodes.update([u, v])\n",
    "            if len(selected_pairs) == num_pairs:\n",
    "                break\n",
    "    if len(selected_pairs) < num_pairs:\n",
    "        raise ValueError(f\"Not enough disjoint edge pairs available. Needed: {num_pairs}, Found: {len(selected_pairs)}\")\n",
    "    return selected_pairs\n",
    "\n",
    "def generate_single_graph(degree, num_components, max_nodes_per_component, max_tries=5):\n",
    "    \"\"\"\n",
    "    Generate a single regular graph structured as a tree of regular biconnected components.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_tries):\n",
    "        try:\n",
    "            G = nx.Graph()\n",
    "            tree = nx.random_unlabeled_tree(num_components)\n",
    "            \n",
    "            # Assign unique global node IDs\n",
    "            current_node_id = 0\n",
    "            components_nodes = []\n",
    "            component_available_nodes = {}\n",
    "            connector_nodes = []\n",
    "            cut_edges = []\n",
    "            \n",
    "            # The degree for each component based on the tree\n",
    "            component_degrees = dict(tree.degree())\n",
    "            \n",
    "            for component_id in range(num_components):\n",
    "                connections_required = component_degrees[component_id]\n",
    "                \n",
    "                # Minimum number of nodes required to accommodate connector nodes\n",
    "                min_nodes_i = connections_required * (degree - 1)\n",
    "                min_nodes_i = max(min_nodes_i, degree)\n",
    "                \n",
    "                if min_nodes_i > max_nodes_per_component:\n",
    "                    raise ValueError(f\"Component {component_id}: Required minimum nodes {min_nodes_i} exceeds max_nodes_per_component {max_nodes_per_component}.\")\n",
    "                \n",
    "                n_i = random.randint(min_nodes_i, max_nodes_per_component)\n",
    "                if (n_i * degree) % 2 != 0:\n",
    "                    if n_i < max_nodes_per_component:\n",
    "                        n_i += 1\n",
    "                    else:\n",
    "                        n_i -= 1\n",
    "                    if (n_i * degree) % 2 != 0 or n_i < min_nodes_i:\n",
    "                        raise ValueError(f\"Component {component_id}: Cannot adjust number of nodes to satisfy regularity.\")\n",
    "                \n",
    "                component_graph = generate_regular_biconnected_graph(degree, n_i)\n",
    "                \n",
    "                # Relabel nodes to have unique global IDs\n",
    "                mapping = {node: node + current_node_id for node in component_graph.nodes()}\n",
    "                component_graph = nx.relabel_nodes(component_graph, mapping)\n",
    "                \n",
    "                G = nx.compose(G, component_graph)\n",
    "                component_node_list = list(component_graph.nodes())\n",
    "                components_nodes.append(component_node_list)\n",
    "                component_available_nodes[component_id] = set(component_node_list)\n",
    "                current_node_id += n_i\n",
    "            \n",
    "            # process edges to connect components\n",
    "            for edge in tree.edges():\n",
    "                u, v = edge  # Component indices\n",
    "                num_pairs = (degree - 1)//2\n",
    "                \n",
    "                # Connector for component u\n",
    "                c_u = current_node_id\n",
    "                current_node_id += 1\n",
    "                # Select d-1 available nodes from component u\n",
    "                available_u = list(component_available_nodes[u])\n",
    "                if len(available_u) < (degree - 1):\n",
    "                    raise ValueError(f\"Component {u}: Not enough available nodes to connect connector node.\")\n",
    "                \n",
    "                pairs_u = find_disjoint_edge_pairs(G.subgraph(available_u), num_pairs)\n",
    "                for (node1, node2) in pairs_u:\n",
    "\n",
    "                    G.remove_edge(node1, node2)\n",
    "                    G.add_edge(c_u, node1)\n",
    "                    G.add_edge(c_u, node2)\n",
    "                    component_available_nodes[u].remove(node1)\n",
    "                    component_available_nodes[u].remove(node2)\n",
    "                \n",
    "                # Connector for component v\n",
    "                c_v = current_node_id\n",
    "                current_node_id += 1\n",
    "                # Select d-1 available nodes from component v\n",
    "                available_v = list(component_available_nodes[v])\n",
    "                if len(available_v) < (degree - 1):\n",
    "                    raise ValueError(f\"Component {v}: Not enough available nodes to connect connector node.\")\n",
    "                \n",
    "                pairs_v = find_disjoint_edge_pairs(G.subgraph(available_v), num_pairs)\n",
    "                for (node1, node2) in pairs_v:\n",
    "                    G.remove_edge(node1, node2)\n",
    "                    G.add_edge(c_v, node1)\n",
    "                    G.add_edge(c_v, node2)\n",
    "                    component_available_nodes[v].remove(node1)\n",
    "                    component_available_nodes[v].remove(node2)\n",
    "\n",
    "                \n",
    "                # Connect the two connector nodes\n",
    "                G.add_edge(c_u, c_v)\n",
    "                cut_edges.extend([(c_u, c_v), (c_v, c_u)])\n",
    "                # Mark as cut vertices\n",
    "                connector_nodes.extend([c_u, c_v])\n",
    "            \n",
    "            for node, deg in G.degree():\n",
    "                if deg != degree:\n",
    "                    \n",
    "                    raise ValueError(f\"Node {node} has degree {deg}, expected {degree}.\")\n",
    "            \n",
    "            return G, connector_nodes, cut_edges\n",
    "        except ValueError as e:\n",
    "            if attempt < max_tries - 1:\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "def transform_to_torch_geometric_data(G, cut_vertices, cut_edges):\n",
    "    \"\"\"\n",
    "    Transform a networkx graph into a torch_geometric.data.Data object.\n",
    "    \"\"\"\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    x = torch.tensor([[i] for i in range(num_nodes)], dtype=torch.long)\n",
    "    \n",
    "    # Initialize labels\n",
    "    y = torch.zeros(121, dtype=torch.long) # Use 121 for compatibility\n",
    "    y[cut_vertices] = 1\n",
    "    \n",
    "    # Get edge list\n",
    "    edge_index = torch.tensor(list(G.edges()), dtype=torch.long).t().contiguous()\n",
    "    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "    # Initialize edge labels\n",
    "    edge_labels = torch.zeros(304, dtype=torch.float) # Hard code 304 for compatibility\n",
    "    # Check for cut edges\n",
    "    for idx in range(num_edges*2):\n",
    "        if (edge_index[0, idx], edge_index[1, idx]) in cut_edges:\n",
    "            edge_labels[idx] = 1\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=y, edge_labels=edge_labels)\n",
    "    return data\n",
    "\n",
    "def generate_dataset(num_graphs, degree, num_components, max_nodes_per_component):\n",
    "    \"\"\"\n",
    "    Generate a dataset of torch_geometric.data.Data objects with cut vertices and cut edges.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for graph_idx in range(num_graphs):\n",
    "        try:\n",
    "            G, cut_vertices, cut_edges = generate_single_graph(\n",
    "                degree=degree,\n",
    "                num_components=num_components,\n",
    "                max_nodes_per_component=max_nodes_per_component\n",
    "            )\n",
    "            data = transform_to_torch_geometric_data(G, cut_vertices, cut_edges)\n",
    "            dataset.append(data)\n",
    "        except ValueError as e:\n",
    "            pass\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Information:\n",
      "Number of nodes: 26\n",
      "Number of edges: 65\n",
      "shape of x: torch.Size([26, 1])\n",
      "first elements of x: tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "Node labels (y):\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "graph: Data(x=[26, 1], edge_index=[2, 130], y=[121], edge_labels=[304])\n",
      "edge index: tensor([[ 0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  4,  4,  6,\n",
      "          6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9,  9, 10, 10, 10,\n",
      "         11, 11, 11, 14, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17,\n",
      "         18, 18, 18, 18, 19, 19, 20, 20, 21, 22, 24,  1,  4,  3,  2,  5,  5,  4,\n",
      "          3, 22,  4,  3,  5, 22,  5, 22,  5, 22,  8,  7, 10, 12, 24, 12,  8, 11,\n",
      "         13, 11, 13,  9, 10, 13, 12, 24, 12, 13, 24, 13, 12, 24, 19, 15, 21, 17,\n",
      "         23, 17, 16, 19, 23, 18, 17, 20, 25, 21, 25, 20, 19, 21, 25, 20, 25, 21,\n",
      "         23, 23, 23, 25],\n",
      "        [ 1,  4,  3,  2,  5,  5,  4,  3, 22,  4,  3,  5, 22,  5, 22,  5, 22,  8,\n",
      "          7, 10, 12, 24, 12,  8, 11, 13, 11, 13,  9, 10, 13, 12, 24, 12, 13, 24,\n",
      "         13, 12, 24, 19, 15, 21, 17, 23, 17, 16, 19, 23, 18, 17, 20, 25, 21, 25,\n",
      "         20, 19, 21, 25, 20, 25, 21, 23, 23, 23, 25,  0,  0,  0,  0,  0,  1,  1,\n",
      "          1,  1,  2,  2,  2,  2,  3,  3,  4,  4,  6,  6,  6,  6,  6,  7,  7,  7,\n",
      "          7,  8,  8,  8,  9,  9,  9,  9, 10, 10, 10, 11, 11, 11, 14, 14, 14, 14,\n",
      "         14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 20,\n",
      "         20, 21, 22, 24]])\n",
      "edge labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Total graphs generated: 588\n"
     ]
    }
   ],
   "source": [
    "rand_dataset = []\n",
    "max_nodes_per_component = 10  # Must be >= degree\n",
    "num_graphs = 123  # Number of graphs in the dataset, total ~580. ideally 116 per num_cmpn\n",
    "\n",
    "degree_list = [5, 3, 5, 3, 3] # random sequence of 3 and 5\n",
    "# Generate dataset\n",
    "for num_cmpn in range(3, 8):\n",
    "    dataset = generate_dataset(\n",
    "    num_graphs=num_graphs,\n",
    "    degree=degree_list[num_cmpn - 3],\n",
    "    num_components=num_cmpn,\n",
    "    max_nodes_per_component=max_nodes_per_component\n",
    "    )\n",
    "    rand_dataset.extend(dataset)\n",
    "\n",
    "if len(rand_dataset) > 0:\n",
    "    graph = rand_dataset[0]\n",
    "    print(\"Graph Information:\")\n",
    "    print(f\"Number of nodes: {graph.num_nodes}\")\n",
    "    print(f\"Number of edges: {graph.num_edges // 2}\")  # Since edges are duplicated\n",
    "    #print(f\"Node features (x):\\n{graph.x}\")\n",
    "    print(f\"shape of x: {graph.x.shape}\")\n",
    "    print(f\"first elements of x: {graph.x[:5]}\")\n",
    "    print(f\"Node labels (y):\\n{graph.y}\")\n",
    "    print(f\"graph: {graph}\")\n",
    "    print(f\"edge index: {graph.edge_index}\")\n",
    "    print(f\"edge labels: {graph.edge_labels}\")\n",
    "    print(f\"Total graphs generated: {len(rand_dataset)}\")\n",
    "else:\n",
    "    print(\"No graphs were generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "max_edges = 0\n",
    "for graph in rand_dataset:\n",
    "    num_edges = graph.edge_index.shape[1]\n",
    "    if num_edges > max_edges:\n",
    "        max_edges = num_edges\n",
    "print(max_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_g1_edges(m, k):\n",
    "    \"\"\"\n",
    "    Build the undirected edges for G1 in 0-based indexing.\n",
    "    Returns a list of (i, j) with i <-> j.\n",
    "    \"\"\"\n",
    "    n = 2 * k * m + 1\n",
    "    edges = []\n",
    "    \n",
    "    # if i0 < 2km-1, next = i0+1, else next=0 => forms a cycle.\n",
    "    num_cycle_nodes = 2 * k * m  # = 2km\n",
    "    for i0 in range(num_cycle_nodes):\n",
    "        j0 = (i0 + 1) % num_cycle_nodes\n",
    "        edges.append((i0, j0))\n",
    "    \n",
    "    n0 = num_cycle_nodes  # 2km\n",
    "    for i in range(1, num_cycle_nodes + 1):\n",
    "        if i % m == 0:\n",
    "            i0 = i - 1  # 0-based\n",
    "            edges.append((n0, i0))\n",
    "    \n",
    "    undirected = []\n",
    "    for (a, b) in edges:\n",
    "        undirected.append((a, b))\n",
    "        undirected.append((b, a))\n",
    "    return undirected\n",
    "\n",
    "def build_g2_edges(m, k):\n",
    "    \"\"\"\n",
    "    Build the undirected edges for G2 in 0-based indexing.\n",
    "    \"\"\"\n",
    "    n = 2 * k * m + 1\n",
    "    edges = []\n",
    "    \n",
    "    num_cycle = k * m\n",
    "    for i0 in range(num_cycle):\n",
    "        j0 = (i0 + 1) % num_cycle\n",
    "        edges.append((i0, j0))\n",
    "    \n",
    "    for i0 in range(num_cycle):\n",
    "        # shift by km\n",
    "        shifted_i0 = i0 + num_cycle\n",
    "        shifted_j0 = ((i0 + 1) % num_cycle) + num_cycle\n",
    "        edges.append((shifted_i0, shifted_j0))\n",
    "    \n",
    "    n0 = 2 * k * m\n",
    "    for i in range(1, 2 * k * m + 1):\n",
    "        if i % m == 0:\n",
    "            i0 = i - 1\n",
    "            edges.append((n0, i0))\n",
    "    \n",
    "    undirected = []\n",
    "    for (a, b) in edges:\n",
    "        undirected.append((a, b))\n",
    "        undirected.append((b, a))\n",
    "    return undirected\n",
    "\n",
    "def make_edge_index_and_labels(edges, max_edges=152):\n",
    "    \"\"\"\n",
    "    Given a list of directed edges (i, j), get edge_index with shape [2, E] and edge-labels of 0s.\n",
    "    \"\"\"\n",
    "    edges = list(dict.fromkeys(edges))  # preserves order\n",
    "    E = len(edges)\n",
    "\n",
    "    edge_index = torch.zeros((2, E), dtype=torch.long)\n",
    "    for idx, (i, j) in enumerate(edges):\n",
    "        edge_index[0, idx] = i\n",
    "        edge_index[1, idx] = j\n",
    "    \n",
    "    edge_labels = torch.zeros(304, dtype=torch.long)\n",
    "    return edge_index, edge_labels, E\n",
    "\n",
    "def set_labels_for_G2(y, edge_labels, edges, m, k):\n",
    "    \"\"\"\n",
    "    Set edge labels for G2 family based on whether edge is cut edge.\n",
    "    \"\"\"\n",
    "    # Careful when converting 0 and 1 based nodes\n",
    "    n_1 = 2*m*k\n",
    "    if k != 1:\n",
    "        y[n_1] = 1\n",
    "    else:\n",
    "        y[m - 1] = 1\n",
    "        y[2*m - 1] = 1\n",
    "        y[n_1] = 1\n",
    "        \n",
    "        special_pairs = [\n",
    "            (m - 1, n_1),\n",
    "            (2*m - 1, n_1),\n",
    "            (n_1, m - 1),\n",
    "            (n_1, 2*m - 1),\n",
    "        ]\n",
    "        edge_to_index = {}\n",
    "        for idx, (src, dst) in enumerate(edges):\n",
    "            edge_to_index[(src, dst)] = idx\n",
    "        \n",
    "        for (a, b) in special_pairs:\n",
    "            if (a, b) in edge_to_index:\n",
    "                idx = edge_to_index[(a, b)]\n",
    "                if idx < 304:  # safety check\n",
    "                    edge_labels[idx] = 1\n",
    "\n",
    "# Whole family construction\n",
    "def build_family_c9():\n",
    "    familyc9_1 = []\n",
    "    familyc9_2 = []\n",
    "    \n",
    "    max_num_nodes = 121  # largest possible n = 2*4*15 + 1\n",
    "    for m in range(1, 20):\n",
    "        for k in range(1, 20):\n",
    "            if m * k < 3 or m * k > 60:\n",
    "                continue\n",
    "            n = 2 * k * m + 1\n",
    "            # G1\n",
    "            edges_g1 = build_g1_edges(m, k)\n",
    "            edge_index_g1, edge_labels_g1, E1 = make_edge_index_and_labels(edges_g1)\n",
    "            x_g1 = torch.tensor([[i] for i in range(n)], dtype=torch.long)\n",
    "            # y: length 289, all zeros for G1\n",
    "            y_g1 = torch.zeros(max_num_nodes, dtype=torch.long)\n",
    "            data_g1 = Data(\n",
    "                x=x_g1,\n",
    "                edge_index=edge_index_g1,\n",
    "                y=y_g1,\n",
    "                edge_labels=edge_labels_g1\n",
    "            )\n",
    "            familyc9_1.append(data_g1)\n",
    "            \n",
    "            # G2\n",
    "            edges_g2 = build_g2_edges(m, k)\n",
    "            edge_index_g2, edge_labels_g2, E2 = make_edge_index_and_labels(edges_g2)\n",
    "            \n",
    "            x_g2 = torch.tensor([[i] for i in range(n)], dtype=torch.long)\n",
    "            y_g2 = torch.zeros(max_num_nodes, dtype=torch.long)\n",
    "            \n",
    "            # Label cut edges\n",
    "            set_labels_for_G2(y_g2, edge_labels_g2, edges_g2, m, k)\n",
    "            data_g2 = Data(\n",
    "                x=x_g2,\n",
    "                edge_index=edge_index_g2,\n",
    "                y=y_g2,\n",
    "                edge_labels=edge_labels_g2\n",
    "            )\n",
    "            familyc9_2.append(data_g2)\n",
    "    \n",
    "    return familyc9_1, familyc9_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in familyc9_1: 152\n",
      "Number of graphs in familyc9_2: 152\n",
      "Data(x=[7, 1], edge_index=[2, 24], y=[121], edge_labels=[304])\n",
      "Data(x=[7, 1], edge_index=[2, 24], y=[121], edge_labels=[304])\n",
      "Data(x=[9, 1], edge_index=[2, 32], y=[121], edge_labels=[304])\n",
      "Data(x=[9, 1], edge_index=[2, 32], y=[121], edge_labels=[304])\n",
      "Data(x=[11, 1], edge_index=[2, 40], y=[121], edge_labels=[304])\n",
      "Data(x=[11, 1], edge_index=[2, 40], y=[121], edge_labels=[304])\n"
     ]
    }
   ],
   "source": [
    "familyc9_1, familyc9_2 = build_family_c9()\n",
    "    \n",
    "print(\"Number of graphs in familyc9_1:\", len(familyc9_1))\n",
    "print(\"Number of graphs in familyc9_2:\", len(familyc9_2))\n",
    "# Example: print one of them\n",
    "for i in range(3):\n",
    "    print(familyc9_1[i])\n",
    "    print(familyc9_2[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_g1_edges(m: int):\n",
    "    \"\"\"\n",
    "    Build the list of undirected edges for G1 (0-based).\n",
    "    G1 has n = 2m nodes forming a cycle, plus an edge connecting (m-1) and (2m-1).\n",
    "    \"\"\"\n",
    "    n = 2 * m\n",
    "    edges = []\n",
    "    \n",
    "    for i0 in range(n):\n",
    "        j0 = (i0 + 1) % n\n",
    "        edges.append((i0, j0))\n",
    "    \n",
    "    edges.append((m - 1, 2*m - 1))\n",
    "    undirected = []\n",
    "    for (a, b) in edges:\n",
    "        undirected.append((a, b))\n",
    "        undirected.append((b, a))\n",
    "    \n",
    "    return undirected\n",
    "\n",
    "def build_g2_edges(m: int):\n",
    "    \"\"\"\n",
    "    Build the list of undirected edges for G2 (0-based).\n",
    "    G2 has two cycles joined by a cut edge.\n",
    "    \"\"\"\n",
    "    n = 2 * m\n",
    "    edges = []\n",
    "    \n",
    "    for i0 in range(m):\n",
    "        j0 = (i0 + 1) % m\n",
    "        edges.append((i0, j0))\n",
    " \n",
    "    for i0 in range(m):\n",
    "        j0 = (i0 + 1) % m\n",
    "        # shift by m\n",
    "        edges.append((i0 + m, j0 + m))\n",
    "    \n",
    "    edges.append((m - 1, 2*m - 1))\n",
    "    undirected = []\n",
    "    for (a, b) in edges:\n",
    "        undirected.append((a, b))\n",
    "        undirected.append((b, a))\n",
    "    \n",
    "    return undirected\n",
    "\n",
    "def make_edge_index_and_labels(edges, max_undirected=121):\n",
    "    \"\"\"\n",
    "    Given a list of directed edges (a, b), buildedge_index, edge_labels.\n",
    "    \"\"\"\n",
    "\n",
    "    edges = list(dict.fromkeys(edges))\n",
    "    \n",
    "    E = len(edges)\n",
    "    # edge_index\n",
    "    edge_index = torch.zeros((2, E), dtype=torch.long)\n",
    "    for idx, (src, dst) in enumerate(edges):\n",
    "        edge_index[0, idx] = src\n",
    "        edge_index[1, idx] = dst\n",
    "    edge_labels = torch.zeros(304, dtype=torch.long) # 304 for compatibility with c9\n",
    "    \n",
    "    return edge_index, edge_labels, edges\n",
    "\n",
    "def build_family_c10():\n",
    "    \"\"\"\n",
    "    Build two lists of Data objects: familyc10_1 (for G1) and familyc10_2 (for G2).\n",
    "    m goes from 3 to 60 (inclusive).\n",
    "    \"\"\"\n",
    "    familyc10_1 = []\n",
    "    familyc10_2 = []\n",
    "    \n",
    "    max_num_nodes = 121   # =120 for m=60 but 121 for compatibility with c9 familites\n",
    "    for m in range(3, 61):\n",
    "        n = 2 * m\n",
    "        \n",
    "        # G1\n",
    "        edges_g1 = build_g1_edges(m)\n",
    "        edge_index_g1, edge_labels_g1, deduped_g1 = make_edge_index_and_labels(edges_g1)\n",
    "        \n",
    "        x_g1 = torch.tensor([[i] for i in range(n)], dtype=torch.long)\n",
    "        # y all zeros for familyc10_1\n",
    "        y_g1 = torch.zeros(max_num_nodes, dtype=torch.long)\n",
    "        \n",
    "        data_g1 = Data(\n",
    "            x=x_g1,\n",
    "            edge_index=edge_index_g1,\n",
    "            y=y_g1,\n",
    "            edge_labels=edge_labels_g1\n",
    "        )\n",
    "        familyc10_1.append(data_g1)\n",
    "        \n",
    "        # G2\n",
    "        edges_g2 = build_g2_edges(m)\n",
    "        edge_index_g2, edge_labels_g2, deduped_g2 = make_edge_index_and_labels(edges_g2)\n",
    "        \n",
    "        x_g2 = torch.tensor([[i] for i in range(n)], dtype=torch.long)\n",
    "        \n",
    "        # Set the (m-1) and (2m-1) entries in 0-based to 1\n",
    "        y_g2 = torch.zeros(max_num_nodes, dtype=torch.long)\n",
    "        y_g2[m-1] = 1\n",
    "        y_g2[2*m - 1] = 1\n",
    "        \n",
    "        # Set the edge_labels\n",
    "        edge_to_idx = {}\n",
    "        for idx, (src, dst) in enumerate(deduped_g2):\n",
    "            edge_to_idx[(src, dst)] = idx\n",
    "        \n",
    "        cut_edges = [\n",
    "            (m - 1, 2*m - 1),\n",
    "            (2*m - 1, m - 1),\n",
    "        ]\n",
    "        for (a, b) in cut_edges:\n",
    "            if (a, b) in edge_to_idx:\n",
    "                idx = edge_to_idx[(a, b)]\n",
    "                if idx < 242:  # just a safety check\n",
    "                    edge_labels_g2[idx] = 1\n",
    "        \n",
    "        data_g2 = Data(\n",
    "            x=x_g2,\n",
    "            edge_index=edge_index_g2,\n",
    "            y=y_g2,\n",
    "            edge_labels=edge_labels_g2\n",
    "        )\n",
    "        familyc10_2.append(data_g2)\n",
    "    \n",
    "    return familyc10_1, familyc10_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in familyc10_1: 58\n",
      "Number of graphs in familyc10_2: 58\n",
      "Data(x=[6, 1], edge_index=[2, 14], y=[121], edge_labels=[304])\n",
      "Data(x=[6, 1], edge_index=[2, 14], y=[121], edge_labels=[304])\n",
      "Data(x=[8, 1], edge_index=[2, 18], y=[121], edge_labels=[304])\n",
      "Data(x=[8, 1], edge_index=[2, 18], y=[121], edge_labels=[304])\n",
      "Data(x=[10, 1], edge_index=[2, 22], y=[121], edge_labels=[304])\n",
      "Data(x=[10, 1], edge_index=[2, 22], y=[121], edge_labels=[304])\n"
     ]
    }
   ],
   "source": [
    "familyc10_1, familyc10_2 = build_family_c10()\n",
    "    \n",
    "print(\"Number of graphs in familyc10_1:\", len(familyc10_1))\n",
    "print(\"Number of graphs in familyc10_2:\", len(familyc10_2))\n",
    "# Example: print one of them\n",
    "for i in range(3):\n",
    "    print(familyc10_1[i])\n",
    "    print(familyc10_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "max_edges = 0\n",
    "for graph in familyc9_2:\n",
    "    num_edges = graph.edge_index.shape[1]\n",
    "    if num_edges > max_edges:\n",
    "        max_edges = num_edges\n",
    "print(max_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008\n"
     ]
    }
   ],
   "source": [
    "biconn_dataset = rand_dataset + familyc9_1 + familyc9_2 + familyc10_1 + familyc10_2\n",
    "print(len(biconn_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle \n",
    "from random import shuffle\n",
    "shuffle(biconn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file \n",
    "import pickle\n",
    "# Save the list of torch data objects to a file\n",
    "with open('biconn_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(biconn_dataset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[28, 1], edge_index=[2, 84], y=[121], edge_labels=[304])\n",
      "Data(x=[28, 1], edge_index=[2, 84], y=[304])\n"
     ]
    }
   ],
   "source": [
    "with open('biconn_dataset.pkl', 'rb') as f:\n",
    "    loaded_biconn_dataset = pickle.load(f)\n",
    "print(loaded_biconn_dataset[0])\n",
    "\n",
    "# reassign edge_labels to y to construct edges dataset\n",
    "edges_dataset = []\n",
    "for dat in loaded_biconn_dataset:\n",
    "    new_dat = Data(\n",
    "        x=dat.x,\n",
    "        edge_index=dat.edge_index,\n",
    "        y=dat.edge_labels\n",
    "    )\n",
    "    edges_dataset.append(new_dat)\n",
    "\n",
    "print(edges_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('biconn_edges_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(edges_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
